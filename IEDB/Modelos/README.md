# Sistema Generalizado de Treinamento de Modelos para HIV

Este sistema permite treinar modelos de proteÃ­nas de forma flexÃ­vel, suportando diferentes datasets e tipos de modelos atravÃ©s de parÃ¢metros **TOTALMENTE CONFIGURÃVEIS** no `main.py`.

## ðŸš€ CaracterÃ­sticas

- **Datasets suportados**: B, MHC1, MHC2
- **Modelos suportados**: 
  - ESMC: `esmc_300m`, `esmc_600m`
  - ESM2: `esm2_t33_650M_UR50D`, `esm2_t36_3B_UR50D`
- **Tipos de vÃ­rus**: Tudo, Virus, Lent, Retro
- **ðŸ†• HIPERPARÃ‚METROS TOTALMENTE CONFIGURÃVEIS** no `main.py`
- **Controle completo** de learning rate, batch size, dropout, etc.
- **Conjuntos de teste especÃ­ficos HIV** para avaliaÃ§Ã£o independente
- **CritÃ©rio inteligente** para melhor modelo (F1 + Precision combinados)
- **Logging com Weights & Biases**
- **Suporte a avaliaÃ§Ã£o e treinamento**

## ðŸ†• NOVA FUNCIONALIDADE: HiperparÃ¢metros ConfigurÃ¡veis

**AGORA VOCÃŠ TEM CONTROLE TOTAL** sobre todos os hiperparÃ¢metros diretamente no `main.py`!

### ðŸ”§ Duas formas de configurar:

1. **Editando defaults no `main.py`** (Recomendado para uso frequente)
2. **Argumentos da linha de comando** (Para overrides especÃ­ficos)

### ðŸ“ ConfiguraÃ§Ã£o de Defaults no main.py

Edite a seÃ§Ã£o no inÃ­cio do `main.py` para seus valores preferidos:

```python
# â”€â”€â”€â”€â”€â”€ ConfiguraÃ§Ã£o bÃ¡sica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_DATASET = "B"                          # Dataset preferido
DEFAULT_MODEL = "esmc_300m"                     # Modelo preferido
DEFAULT_VIRUS_TYPE = "Base"                     # Tipo de arquivo
DEFAULT_EVAL_MODE = False                       # Modo padrÃ£o

# â”€â”€â”€â”€â”€â”€ HiperparÃ¢metros de treinamento â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_EPOCHS = 30                            # NÃºmero de Ã©pocas
DEFAULT_LEARNING_RATE = 1e-4                   # Taxa de aprendizado
DEFAULT_WEIGHT_DECAY = 0.01                    # RegularizaÃ§Ã£o L2
DEFAULT_BATCH_SIZE = None                      # None = auto
DEFAULT_MAX_LENGTH = None                      # None = auto

# â”€â”€â”€â”€â”€â”€ ConfiguraÃ§Ã£o do modelo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_DROPOUT = None                         # None = auto
DEFAULT_FREEZE_BACKBONE = False                # Congelar encoder

# â”€â”€â”€â”€â”€â”€ Pesos da loss function para precision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_POS_CLASS_WEIGHT = 3.0                # > 1.0 = melhor precision
DEFAULT_LOSS_WEIGHT_MULTIPLIER = 1.0          # Multiplicador adicional
```

**Depois execute simplesmente:** `python main.py`

## ðŸ†• W&B Hyperparameter Sweep para OtimizaÃ§Ã£o AutomÃ¡tica

**NOVO**: Sistema de otimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros focado em **melhorar precision**!

### ðŸŽ¯ O que Ã© o Sweep?

O **W&B Hyperparameter Sweep** testa automaticamente diferentes combinaÃ§Ãµes de hiperparÃ¢metros para encontrar a configuraÃ§Ã£o que **maximiza a precision** sem perder F1-score.

### ðŸš€ Como usar:

#### MÃ©todo 1: Editar defaults
```python
# No main.py:
DEFAULT_SWEEP_MODE = True
DEFAULT_DATASET = "B"
DEFAULT_MODEL = "esmc_300m"
DEFAULT_EPOCHS = 5  # RÃ¡pido para sweep
```
```bash
python main.py  # Inicia sweep automaticamente
```

#### MÃ©todo 2: Argumento direto
```bash
python main.py --sweep --dataset B --model esmc_300m
```

### ðŸ”§ O que o Sweep otimiza:

**Foco Principal** (pesos da loss function):
- `pos_class_weight`: 1.0 â†’ 10.0 (peso para melhorar precision)
- `loss_weight_multiplier`: 0.5 â†’ 3.0 (multiplicador de efeito)

**SecundÃ¡rio**:
- `learning_rate`: 1e-6 â†’ 1e-3 (taxa de aprendizado)
- `weight_decay`: 0.0 â†’ 0.1 (regularizaÃ§Ã£o L2)
- `dropout`: 0.0 â†’ 0.5 (regularizaÃ§Ã£o do modelo)

**Mantido fixo** (para estabilidade):
- `batch_size`, `max_length`, `epochs`

### ðŸ“Š MÃ©trica otimizada:
- **`f1_precision_combined`**: MÃ©dia harmÃ´nica de F1 e Precision
- **Objetivo**: Precision alta SEM perder F1

### ðŸŒ Acompanhamento:
O sweep cria automaticamente um projeto W&B e exibe o link para acompanhar:
```
âœ… Sweep criado com ID: abc123
ðŸŒ Acompanhe em: https://wandb.ai/sua-conta/protein-b-sweep/sweeps/abc123
```

### ðŸ“‹ Arquivos do Sweep:
- `sweep_config.yaml` - ConfiguraÃ§Ã£o dos hiperparÃ¢metros
- `sweep_guide.md` - Guia detalhado de uso

**Depois execute simplesmente:** `python main.py`

## ðŸ“ Estrutura de Arquivos

```
Modelos/
â”œâ”€â”€ main.py              # Script principal
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes generalizadas
â”œâ”€â”€ trainer.py           # Classe de treinamento
â”œâ”€â”€ models.py            # DefiniÃ§Ãµes de modelos
â”œâ”€â”€ dataset.py           # Dataset personalizado
â”œâ”€â”€ B/                   # Dataset B
â”‚   â”œâ”€â”€ simB*.txt       # Arquivos positivos de treino
â”‚   â”œâ”€â”€ naoB*.txt       # Arquivos negativos de treino
â”‚   â””â”€â”€ model/          # Modelos salvos
â”œâ”€â”€ MHC1/               # Dataset MHC1
â”‚   â”œâ”€â”€ simMHC1*.txt    # Arquivos positivos de treino
â”‚   â”œâ”€â”€ naoMHC1*.txt    # Arquivos negativos de treino
â”‚   â””â”€â”€ model/          # Modelos salvos
â”œâ”€â”€ MHC2/               # Dataset MHC2
â”‚   â”œâ”€â”€ simMHC2*.txt    # Arquivos positivos de treino
â”‚   â”œâ”€â”€ naoMHC2*.txt    # Arquivos negativos de treino
â”‚   â””â”€â”€ model/          # Modelos salvos
â””â”€â”€ ../Inferencia_HIV/  # Conjuntos de teste especÃ­ficos
    â”œâ”€â”€ Bcell/
    â”‚   â”œâ”€â”€ simBHIV.txt     # Teste positivo B
    â”‚   â””â”€â”€ naoBHIV.txt     # Teste negativo B
    â”œâ”€â”€ MHC1/
    â”‚   â”œâ”€â”€ simMHC1HIV.txt  # Teste positivo MHC1
    â”‚   â””â”€â”€ naoMHC1HIV.txt  # Teste negativo MHC1
    â””â”€â”€ MHC2/
        â”œâ”€â”€ simMHC2HIV.txt  # Teste positivo MHC2
        â””â”€â”€ naoMHC2HIV.txt  # Teste negativo MHC2
```

## ðŸ› ï¸ Como Usar

### ðŸ†• ConfiguraÃ§Ã£o FlexÃ­vel de HiperparÃ¢metros

**NOVO**: Agora vocÃª controla TODOS os hiperparÃ¢metros diretamente no `main.py`!

#### MÃ©todo 1: Editar Defaults (Recomendado)

Edite os defaults no topo do `main.py` e execute simplesmente:

```bash
python main.py  # Usa seus defaults configurados
```

#### MÃ©todo 2: Argumentos da Linha de Comando

Override qualquer hiperparÃ¢metro especÃ­fico:

```bash
# Controle completo via argumentos
python main.py \
    --dataset B \
    --model esmc_300m \
    --virus-type Base \
    --epochs 20 \
    --lr 5e-4 \
    --batch-size 6 \
    --max-length 80 \
    --dropout 0.3 \
    --pos-class-weight 2.5
```

### ConfiguraÃ§Ã£o RÃ¡pida (sem argumentos)

Para facilitar o uso, edite a seÃ§Ã£o de defaults no topo do `main.py`:

```python
# ðŸ”§ CONFIGURAÃ‡ÃƒO DE DEFAULTS
DEFAULT_DATASET = "B"                    # "B", "MHC1", "MHC2"
DEFAULT_MODEL = "esmc_300m"              # Modelo a usar
DEFAULT_VIRUS_TYPE = "Base"              # "Base", "Tudo", "Virus", "Lent", "Retro"
DEFAULT_EPOCHS = 30                      # NÃºmero de Ã©pocas
DEFAULT_EVAL_MODE = False                # False = treino, True = avaliaÃ§Ã£o

# Para modo AVALIAÃ‡ÃƒO: especifique a run que quer testar
DEFAULT_RUN_NAME = None                  # Ex: "B_Base_esmc_300m_20241218_143022" ou None para mais recente
```

**Exemplos de uso:**

```bash
# 1. Treino com defaults
python main.py  # Usa os defaults configurados

# 2. AvaliaÃ§Ã£o automÃ¡tica (mais recente)
# DEFAULT_EVAL_MODE = True
# DEFAULT_RUN_NAME = None  
python main.py  # Usa o modelo mais recente

# 3. AvaliaÃ§Ã£o de modelo especÃ­fico
# DEFAULT_EVAL_MODE = True
# DEFAULT_RUN_NAME = "B_Base_esmc_300m_20241218_143022"
python main.py  # Usa exatamente este modelo
```

### Treinamento

```bash
# Exemplo bÃ¡sico - dataset B com modelo ESMC 300M
python main.py --dataset B --model esmc_300m --virus-type Tudo

# Usar arquivos base (sem sufixo) - simB.txt, naoB.txt
python main.py --dataset B --model esmc_300m --virus-type Base

# Treinar MHC1 com ESM2
python main.py --dataset MHC1 --model esm2_t33_650M_UR50D --virus-type Virus

# Treinar MHC2 com modelo maior
python main.py --dataset MHC2 --model esm2_t36_3B_UR50D --virus-type Lent

# Treino rÃ¡pido (poucas Ã©pocas)
python main.py --dataset B --model esmc_300m --virus-type Base --epochs 5
```

### AvaliaÃ§Ã£o

```bash
# Avaliar melhor modelo treinado (carrega automaticamente o best_model.pt)
python main.py --eval --dataset B --model esmc_300m --virus-type Tudo

# Avaliar checkpoint especÃ­fico
python main.py --eval --dataset MHC1 --model esm2_t33_650M_UR50D --virus-type Virus --step 1500
```

### ParÃ¢metros DisponÃ­veis

#### ðŸ†• CONTROLE TOTAL dos HiperparÃ¢metros

**ConfiguraÃ§Ã£o BÃ¡sica:**
- `--dataset`: Escolha entre `B`, `MHC1`, `MHC2` (default: configurÃ¡vel)
- `--model`: Tipo de modelo a usar (default: configurÃ¡vel)
  - `esmc_300m`: ESM-C 300M parÃ¢metros
  - `esmc_600m`: ESM-C 600M parÃ¢metros  
  - `esm2_t33_650M_UR50D`: ESM2 650M parÃ¢metros
  - `esm2_t36_3B_UR50D`: ESM2 3B parÃ¢metros
- `--virus-type`: Tipo de dados de vÃ­rus (default: configurÃ¡vel)
  - `Base`: Arquivos base sem sufixo (ex: `simB.txt`, `naoB.txt`)
  - `Tudo`: Todos os dados (ex: `simBTudo.txt`, `naoBTudo.txt`)
  - `Virus`: Apenas dados de vÃ­rus (ex: `simBVirus.txt`, `naoBVirus.txt`)
  - `Lent`: Apenas lentivÃ­rus (ex: `simBLent.txt`, `naoBLent.txt`)
  - `Retro`: Apenas retrovÃ­rus (ex: `simBRetro.txt`, `naoBRetro.txt`)

**ðŸ†• HiperparÃ¢metros de Treinamento:**
- `--epochs`: NÃºmero de Ã©pocas de treinamento (default: configurÃ¡vel)
- `--lr`, `--learning-rate`: Taxa de aprendizado (default: configurÃ¡vel)
- `--weight-decay`: RegularizaÃ§Ã£o L2 (default: configurÃ¡vel)
- `--batch-size`: Tamanho do batch (default: auto baseado no modelo)
- `--max-length`: Comprimento mÃ¡ximo das sequÃªncias (default: auto baseado no modelo)

**ðŸ†• ConfiguraÃ§Ã£o do Modelo:**
- `--dropout`: Taxa de dropout (default: auto baseado no modelo)
- `--freeze-backbone`: Congelar pesos do encoder (default: configurÃ¡vel)

**ðŸ†• Pesos da Loss Function:**
- `--pos-class-weight`: Peso para classe negativa para melhorar precision (default: configurÃ¡vel)
- `--loss-weight-multiplier`: Multiplicador escalar para os pesos (default: configurÃ¡vel)

**ðŸ†• Intervalos e Salvamento:**
- `--eval-interval`: Avaliar a cada N Ã©pocas (default: configurÃ¡vel)
- `--save-interval`: Salvar checkpoint a cada N Ã©pocas (default: configurÃ¡vel)

**ðŸ†• Weights & Biases:**
- `--wandb-project`: Nome do projeto W&B (default: auto gerado)
- `--wandb-entity`: OrganizaÃ§Ã£o W&B (default: conta padrÃ£o)

**ðŸ†• Reprodutibilidade:**
- `--seed`: Semente para reprodutibilidade (default: configurÃ¡vel)

**AvaliaÃ§Ã£o:**
- `--eval`: Modo de avaliaÃ§Ã£o (default: False = treinamento)
- `--step`: Step especÃ­fico para avaliaÃ§Ã£o (default: melhor modelo)
- `--run-name`: Run especÃ­fico para avaliar (default: mais recente)
- `--list-runs`: Listar runs disponÃ­veis

## âš™ï¸ ConfiguraÃ§Ãµes AutomÃ¡ticas

O sistema configura automaticamente os hiperparÃ¢metros baseado no modelo escolhido:

### ESMC Models
- **Learning Rate**: 5e-3 (maior para ESMC)
- **Max Length**: 30 (otimizado para peptÃ­deos)
- **Batch Sizes**: 8 (300M), 4 (600M)

### ESM2 Models  
- **Learning Rate**: 1e-5 (menor para ESM2)
- **Max Length**: 30 (otimizado para peptÃ­deos)
- **Batch Sizes**: 6 (650M), 2 (3B)

## ðŸŽ¯ Controle de Precision com Pesos Personalizados

O sistema oferece controle fino sobre a loss function para otimizar a mÃ©trica de precision atravÃ©s de pesos nas classes:

### ParÃ¢metros de Peso

- **`pos_class_weight`** (default: 1.0): Peso aplicado Ã  classe negativa para controle de precision
  - `> 1.0`: Penaliza mais falsos positivos â†’ **melhora precision**
  - `< 1.0`: Penaliza menos falsos positivos â†’ melhora recall
  - `= 1.0`: Pesos balanceados (comportamento padrÃ£o)

- **`loss_weight_multiplier`** (default: 1.0): Multiplicador escalar para amplificar o efeito
  - Multiplica ambos os pesos das classes
  - Ãštil para ajuste fino adicional

### FÃ³rmula dos Pesos (CORRIGIDA)
```
peso_classe_negativa = pos_class_weight * loss_weight_multiplier
peso_classe_positiva = 1.0 * loss_weight_multiplier
```

### Exemplos de ConfiguraÃ§Ã£o

**Peso moderado para melhorar precision:**
```python
trainer = Trainer(
    # ... outros parÃ¢metros
    pos_class_weight=2.0,           # Classe positiva 2x mais penalizada
    loss_weight_multiplier=1.0,     # Sem amplificaÃ§Ã£o adicional
)
# Resultado: pesos [1.0, 2.0]
```

**Peso alto para precision muito conservadora:**
```python
trainer = Trainer(
    # ... outros parÃ¢metros  
    pos_class_weight=5.0,           # Classe positiva 5x mais penalizada
    loss_weight_multiplier=1.5,     # Amplifica o efeito em 1.5x
)
# Resultado: pesos [1.5, 7.5]
```

**Para melhorar recall (menos conservador):**
```python
trainer = Trainer(
    # ... outros parÃ¢metros
    pos_class_weight=0.5,           # Classe positiva menos penalizada
    loss_weight_multiplier=2.0,     # Amplifica o efeito
)
# Resultado: pesos [2.0, 1.0]
```

### RecomendaÃ§Ãµes de Uso

- **Precision baixa**: Use `pos_class_weight=2.0` ou maior
- **Recall baixo**: Use `pos_class_weight=0.5` ou menor  
- **Dataset desbalanceado**: Ajuste baseado na distribuiÃ§Ã£o real
- **Ajuste fino**: Use `loss_weight_multiplier` para amplificar sutilmente

### Monitoramento
Durante o treinamento, o sistema exibe os pesos configurados:
```
ðŸ”§ Loss function configurada:
   Peso classe negativa (0): 1.000
   Peso classe positiva (1): 2.000
   Multiplicador: 1.000
   ðŸ’¡ Peso maior na classe positiva â†’ menos falsos positivos â†’ melhor precision
```

## ðŸŽ¯ CritÃ©rio de Melhor Modelo

O sistema usa um critÃ©rio inteligente para selecionar o melhor modelo:

- **MÃ©trica Combinada**: F1 + Precision (mÃ©dia harmÃ´nica)
- **Objetivo**: Modelos com **F1 alto E Precision alto**
- **Evita**: Modelos com recall alto mas precision baixa
- **Formula**: `2 * (F1 * Precision) / (F1 + Precision)`

Isso garante que o melhor modelo tenha boa performance geral (F1) sem sacrificar a confiabilidade das prediÃ§Ãµes positivas (Precision).

## ðŸ“Š Conjuntos de Dados

### Treinamento
- **Fonte**: Arquivos nas pastas B/, MHC1/, MHC2/
- **100% dos dados**: Todos os dados disponÃ­veis para treino
- **Arquivos**: Baseados no `--virus-type` escolhido
- **Sem validaÃ§Ã£o**: Modelo treina em todos os dados disponÃ­veis

### Teste
- **Fonte**: Arquivos especÃ­ficos em `../Inferencia_HIV/`
- **Independente**: Dados HIV especÃ­ficos para cada dataset
- **Fixo**: Sempre os mesmos arquivos para comparabilidade
- **Caminho**: Inferencia_HIV estÃ¡ no mesmo nÃ­vel que Modelos/

## ðŸ“ˆ Outputs

### Estrutura de SaÃ­da
```
{dataset}/model/{run_name}/
â”œâ”€â”€ best_model.pt               # Melhor modelo baseado no critÃ©rio
â”œâ”€â”€ best_model_info.json       # InformaÃ§Ãµes do melhor modelo
â”œâ”€â”€ pytorch_model_step{N}.pt    # Checkpoints regulares
â”œâ”€â”€ model_metrics.json         # HistÃ³rico completo de mÃ©tricas
â””â”€â”€ run_info.json              # InformaÃ§Ãµes do treinamento
```

### MÃ©tricas Computadas
- **Accuracy**: AcurÃ¡cia geral
- **Precision**: PrecisÃ£o (PPV) - **usado no critÃ©rio**
- **Recall**: Sensibilidade (TPR)
- **Specificity**: Especificidade (TNR)
- **F1**: F1-score - **usado no critÃ©rio**
- **MCC**: Matthews Correlation Coefficient
- **AUC**: Area Under the ROC Curve
- **F1_Precision_Combined**: MÃ©trica combinada para seleÃ§Ã£o

## ðŸ”§ Exemplos de Uso AvanÃ§ado

### 1. Uso com defaults (recomendado para testes rÃ¡pidos)
```bash
# Edite os defaults no main.py uma vez
# DEFAULT_DATASET = "MHC2"
# DEFAULT_MODEL = "esmc_300m" 
# DEFAULT_VIRUS_TYPE = "Base"
# DEFAULT_EPOCHS = 10

# Depois simplesmente execute:
python main.py                    # Treino rÃ¡pido com defaults
python main.py --eval             # AvaliaÃ§Ã£o com defaults
```

### 1.1. Workflow completo com defaults
```bash
# 1. Primeiro treinar alguns modelos
python main.py --epochs 5         # Treino rÃ¡pido
python main.py --epochs 15        # Treino mÃ©dio  
python main.py --epochs 30        # Treino completo

# 2. Ver modelos disponÃ­veis
python main.py --list-runs
# Output: Lista com B_Base_esmc_300m_TIMESTAMP para cada treino

# 3. Configurar default para avaliar modelo especÃ­fico
# Edite no main.py:
# DEFAULT_EVAL_MODE = True
# DEFAULT_RUN_NAME = "B_Base_esmc_300m_20241218_143055"  # Copie da lista

# 4. Avaliar sem argumentos
python main.py                    # Avalia exatamente o modelo configurado!
```

### 2. Comparar diferentes tipos de arquivos no mesmo dataset
```bash
# Comparar arquivo base vs todos os dados
python main.py --dataset B --model esmc_300m --virus-type Base  # simB.txt
python main.py --dataset B --model esmc_300m --virus-type Tudo  # simBTudo.txt
```

### 3. Comparar modelos no mesmo dataset
```bash
# Treinar todos os modelos no dataset B com arquivos base
for model in esmc_300m esmc_600m esm2_t33_650M_UR50D; do
    python main.py --dataset B --model $model --virus-type Base
done
```

### 4. Treinar em todos os datasets
```bash
# Treinar ESMC 300M em todos os datasets com arquivos base
for dataset in B MHC1 MHC2; do
    python main.py --dataset $dataset --model esmc_300m --virus-type Base
done
```

### 5. Experimentos com diferentes tipos de vÃ­rus
```bash
# Testar todos os tipos de vÃ­rus no MHC1
for virus in Base Tudo Virus Lent Retro; do
    python main.py --dataset MHC1 --model esmc_300m --virus-type $virus --epochs 10
done
```

### 6. Avaliar todos os melhores modelos
```bash
# Avaliar os melhores modelos treinados
for dataset in B MHC1 MHC2; do
    python main.py --eval --dataset $dataset --model esmc_300m --virus-type Base
done
```

### 7. Treinamento rÃ¡pido para testes
```bash
# Treinos rÃ¡pidos (5 Ã©pocas) para teste
python main.py --dataset B --model esmc_300m --virus-type Base --epochs 5
python main.py --dataset MHC1 --model esmc_300m --virus-type Virus --epochs 5
python main.py --dataset MHC2 --model esmc_300m --virus-type Lent --epochs 5
```

## ðŸ“ Logs e Monitoramento

- **Weights & Biases**: Logs automÃ¡ticos de treinamento e mÃ©tricas
- **Project Names**: AutomÃ¡tico (`protein-b`, `protein-mhc1`, `protein-mhc2`)
- **Run Names**: Formato `{dataset}_{virus_type}_{model_type}`
- **MÃ©tricas locais**: Salvos em JSON para anÃ¡lise offline
- **Progresso visual**: MÃ©tricas principais mostradas a cada Ã©poca

## ðŸ† Sistema de Melhor Modelo

### Durante o Treinamento
1. A cada Ã©poca, calcula mÃ©tricas no conjunto de teste
2. Computa score combinado F1+Precision
3. Se melhor que anterior, salva como `best_model.pt`
4. MantÃ©m histÃ³rico completo em `best_model_info.json`

### Na AvaliaÃ§Ã£o
1. Por padrÃ£o, carrega `best_model.pt`
2. OpÃ§Ã£o de carregar checkpoint especÃ­fico com `--step`
3. Mostra mÃ©tricas detalhadas e comparativas

## ðŸš¨ Requisitos

- Python 3.8+
- PyTorch
- Transformers
- ESM (para modelos ESMC)
- Weights & Biases
- scikit-learn
- tqdm
- tabulate

## ðŸ’¡ Dicas

1. **Melhor modelo**: O sistema sempre salva o melhor baseado no critÃ©rio F1+Precision
2. **Conjuntos de teste**: SÃ£o especÃ­ficos para HIV e independentes do treinamento
3. **Sem validaÃ§Ã£o**: Treina em 100% dos dados disponÃ­veis, testa apenas no conjunto HIV
4. **AvaliaÃ§Ã£o**: Use `--eval` para testar modelos jÃ¡ treinados
5. **Logs**: Acompanhe o treinamento via Weights & Biases ou outputs locais
6. **Caminho correto**: Inferencia_HIV estÃ¡ no mesmo nÃ­vel que a pasta Modelos/ 